---
title: "Practical Machine Learning:"
subtitle: "Weight Lifting Exercise Quality Classification"
author: "adatum"
date: "April 25, 2016"
output: 
    html_document:
      theme: cerulean
      toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

if (!require("pacman")) install.packages("pacman")
pacman::p_load(caret, caretEnsemble, arm, C50, plyr, earth, mda, gbm, MASS, randomForest, sda, kernlab, xgboost)
# library(caret)
# library(caretEnsemble)
# library(bnclassify)
# library(arm)
# library(C50)
# library(plyr)
# library(earth)
# library(mda)
# library(gbm)
# library(MASS)
# library(randomForest)
# library(sda)
# library(kernlab)
# library(xgboost)
set.seed(42)
```

### Introduction
With wearable heath and fitness devices becoming increasingly popular, and correspondingly, the amount of data collected by such devices burgeoning, the question of how to make use of these vast stores of information holds much potential. Many devices report simple aggregate summaries of the quantity of particular activities performed, perhaps in relation to some goal. On the other hand, assessing the quality of the activities is more challenging and may represent significant untapped potential hidden in the data.

The [Weight Lifting Exercises Dataset](http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises) aims to test the feasibility of assessing the quality of weight lifting exercises performed by inexperienced individuals, potentially as a precursor to personalized digital personal trainers. The data were collected by attaching orientation sensors on a dumbbell and the participant's arm, forearm, and belt. They were then instructed to perform 10 sets of unilateral dumbbell biceps curls in one correct and four incorrect ways: "*exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).*" More details are available at the [researchers' website](http://groupware.les.inf.puc-rio.br/har).

The goal is to develop machine learning algorithms which correctly classify the quality of the exercise performed given the sensor data. We show here an implementation achieving 99.7% overall classification accuracy.

### Data Exploration and Preprocessing

The training and testing data sets are downloaded and read, if not already present.

```{r import-data}
if(!exists("pml_training") & !exists("pml_testing")){
        training_file <- "pml-training.csv"
        testing_file <- "pml-testing.csv"
        
        if(!file.exists(training_file) & !file.exists(testing_file)){
        training_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
        testing_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
        download.file(training_url, training_file, method = "curl")
        download.file(testing_url, testing_file, method = "curl")
        }
        
        pml_training <- read.csv("pml-training.csv", na.strings = c(NA, ""))
        pml_testing <- read.csv("pml-testing.csv", na.strings = c(NA, ""))
}

dim(pml_training)
names(pml_training)
```

To begin, the data are partitioned into training and validation sets. 

```{r partition-data}
ind_training <- createDataPartition(pml_training$classe, p = 0.75, list = F)
training <- pml_training[ind_training, ]
validation <- pml_training[-ind_training, ]

str(training, list.len = 15)
```

A few strategic desicions are made in treating the data. First, we notice that several variables are very sparsely populated. We could impute missing values if there are small gaps, but if the ratio of missing values to non-missing values is high, we will prefer to omit those variables.

```{r missing-values}
rows <- nrow(training)
(na_ratio <- sapply(1:ncol(training), function(x) sum(is.na(training[ , x]))/rows))
(nonsparse <- na_ratio < 0.8)
sum(nonsparse)
```

There are `r ncol(training) - sum(nonsparse)` sparse variables. Eliminating them should make our models simpler and more computationally efficient.

Secondly, although the data were clearly collected as a time series, as the experimental design and timestamp variables show, we will initially attempt a simplification: discarding all time and individual participant information (the first 7 columns/variables in the data), and instead train our algorithms on the snapshot-like non-sequential view of the data. In the event that this approach fails to produce a sufficient level of performance, a time series approach can be adopted.

We implement a custom preprocessing function to keep only the non-sparse variables, eliminate the time and individual data, and move the response variable to the first column for convenience.

```{r preproc}

myPreProc <- function(df, keep.cols, skip.cols = 7) {
    
    proc_df <- df[ , keep.cols][ , -(1:skip.cols)]

    # put response variable in first column
    ncols <- ncol(proc_df)
    proc_df <- proc_df[, c(ncols, 1:(ncols-1))]

    # make all columns (except response) numeric
    proc_df[ , 2:ncols] <- as.data.frame(lapply(proc_df[ , -1], as.numeric))
    
    proc_df
}

pr_training <- myPreProc(training, nonsparse)
pr_validation <- myPreProc(validation, nonsparse)
pr_testing <- myPreProc(pml_testing, nonsparse)

```

The exact same preprocessing that is done to the training set is also done to the validation and testing sets. Note that the testing set does not contain the response variable (correct classes) but a placeholder index which will ultimately be ignored.

### Modeling

One approach to modeling is to try many different types of machine learning algorithms initially, evaluate their performance, and then tune the more successful one(s) as needed. This has the benefit of being data-driven based on empirical results. We will try ten algorithms, several of which use very different underlying approaches to the modeling. The `caretEnsemble` package makes it easy to train many models simultaneously with `caretList`.

5-fold cross-validation is used for choosing model parameters. The training data set is split into 5 stratified groups, with the model trained on 4 of them, and the model's performance tested on the remaining group. The groups are then rotated until each group has been used for testing. Often for better model performance, 10-fold repeated cross-validation is suggested, however, here we begin with 5-fold non-repeated cross-validation in the interest of computational speed, and we will consider more stringent methods if the results indicate the need. `caret` automatically tries several parameter combinations (as required by the model) to build the optimal model. If this fails to produce good results we can later specify the number and values of parameters to try.

```{r model-train}
mycontrol <- trainControl(method = "cv", number = 5)
mymethods <- c("bayesglm", "C5.0", "fda", "gbm", "knn",  "qda", "rf", "sda", "svmPoly", "xgbLinear")
    
start_time <- proc.time()
model_list <- caretList(x = pr_training[ , -1],
                        y = pr_training[ , 1],
                        trControl = mycontrol,
                        methodList = mymethods
                        )

proc.time() - start_time # model training runtime for curiosity
```

Next, the built models are used to make predictions on the validation set to obtain our best unbiased estimates of model performance on unseen data. These results guide the decision of which model(s) to use in the future.

```{r model-performance}
pred_list <- lapply(model_list, function(x) predict(x, newdata = pr_validation[ , -1]))
(accuracy <- sort(sapply(pred_list, function(x) confusionMatrix(x, pr_validation[ , 1])$overall[1]), decreasing = T))
```

Several of the models perform very well with `r print(unlist(strsplit(names(accuracy[1]), split = "\\."))[1], quote = F)` having the highest accuracy. 

### Results

Considering the high accuracies achieved 

### Conclusions


### References
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. [Qualitative Activity Recognition of Weight Lifting Exercises](http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201). Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
