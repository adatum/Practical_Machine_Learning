---
title: "Practical Machine Learning:"
subtitle: "Weight Lifting Exercise Quality Classification"
author: "adatum"
date: "April 25, 2016"
output: 
    html_document:
      theme: cerulean
      toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
library(caret)
set.seed(42)
```

### Introduction
With wearable heath and fitness devices becoming increasingly popular, and correspondingly, the amount of data collected by such devices burgeoning, the question of how to make use of these vast stores of information holds much potential. Many devices report simple aggregate summaries of the quantity of particular activities performed, perhaps in relation to some goal. On the other hand, assessing the quality of the activities is more challenging and may represent significant untapped potential hidden in the data.

The [Weight Lifting Exercises Dataset](http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises) aims to test the feasibility of assessing the quality of weight lifting exercises performed by inexperienced individuals, potentially as a precursor to personalized digital personal trainers. The data were collected by attaching orientation sensors on a dumbbell and the participant's arm, forearm, and belt. They were then instructed to perform 10 sets of unilateral dumbbell biceps curls in one correct and four incorrect ways: "*exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).*" More details are available at the [researchers' website](http://groupware.les.inf.puc-rio.br/har).

The goal is to develop machine learning algorithms which correctly classify the quality of the exercise performed given the sensor data. We show here an implementation achieving 99.69% overall classification accuracy.

### Data Exploration and Preprocessing

The training and testing data sets are downloaded and read, if not already present.

```{r import-data}
if(!exists("pml_training") & !exists("pml_testing")){
        training_file <- "pml-training.csv"
        testing_file <- "pml-testing.csv"
        
        if(!file.exists(training_file) & !file.exists(testing_file)){
        training_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
        testing_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
        download.file(training_url, training_file, method = "curl")
        download.file(testing_url, testing_file, method = "curl")
        }
        
        pml_training <- read.csv("pml-training.csv", na.strings = c(NA, ""))
        pml_testing <- read.csv("pml-testing.csv", na.strings = c(NA, ""))
}

dim(pml_training)
names(pml_training)
```

To begin, the data are partitioned into training and validation sets. 

```{r partition-data}
ind_training <- createDataPartition(pml_training$classe, p = 0.75, list = F)
training <- pml_training[ind_training, ]
validation <- pml_training[-ind_training, ]

str(training, list.len = 15)
```

A few strategic desicions are made in treating the data. First, we notice that several variables are very sparsely populated. We could impute missing values if there are small gaps, but if the ratio of missing values to non-missing values is high, we will prefer to omit those variables.

```{r missing-values}
rows <- nrow(training)
(na_ratio <- sapply(1:ncol(training), function(x) sum(is.na(training[ , x]))/rows))
(nonsparse <- na_ratio < 0.8)
sum(nonsparse)
```

There are `r ncol(training) - sum(nonsparse)` sparse variables. Eliminating them should make our models simpler and more computationally efficient.

Secondly, although the data were clearly collected as a time series, as the experimental design and timestamp variables show, we will initially attempt a simplification: discarding all time and individual participant information (the first 7 columns/variables in the data), and instead train our algorithms on the snapshot-like non-sequential view of the data. In the event that this approach fails to produce a sufficient level of performance, a time series approach can be adopted.

We implement a custom preprocessing function to keep only the non-sparse variables, eliminate the time and individual data, and move the response variable to the first column for convenience.

```{r preproc}

myPreProc <- function(df, keep.cols, skip.cols = 7) {
    
    proc_df <- df[ , keep.cols][ , -(1:skip.cols)]

    # put response variable in first column
    ncols <- ncol(proc_df)
    proc_df <- proc_df[, c(ncols, 1:(ncols-1))]

    # make all columns numeric
    proc_df[ , 2:ncols] <- as.data.frame(lapply(proc_df[ , -1], as.numeric))
    
    proc_df
}

pr_training <- myPreProc(training, nonsparse)
pr_validation <- myPreProc(validation, nonsparse)
pr_testing <- myPreProc(pml_testing, nonsparse)

```

The exact same preprocessing that is done to the training set is also done to the validation and testing sets. Note that the testing set does not contain the response variable (correct classes) but a placeholder index which will ultimately be ignored.

### Modeling

### Results

### Conclusions


### References
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. [Qualitative Activity Recognition of Weight Lifting Exercises](http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201). Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
